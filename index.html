<!DOCTYPE HTML>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="author" content="Zhikang Zou">
  <meta name="description" content="Zhikang Zou's Homepage">
  <meta name="keywords" content="Zhikang Zou,邹智康,homepage,主页,  computer vision">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Zhikang Zou(邹智康)'s Homepage</title>
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zhikang Zou &nbsp; &nbsp;邹智康</name>
              </p>
              <p style="text-align:center">
                <a href="mailto:zhikangzou001@gmail.com'">Email</a>
                &nbsp; &nbsp;&nbsp;&nbsp; <a href="https://scholar.google.com/citations?user=T-YePFgAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp; &nbsp;&nbsp;&nbsp;<a href="https://github.com/BigTeacher-777">Github</a>
              </p>

              <div class="w3-content" style="text-align: justify">
              I am currently working at Baidu Inc. as a computer vision researcher, working closely with <a href='https://shuluoshu.github.io/'>Xiaoqing Ye</a> and <a href='https://scholar.google.com/citations?user=R1rVRUkAAAAJ&hl=zh-CN'>Xiao Tan</a>. I received my bachelor degree and master degree from Huazhong University of Science and Technology in 2020, advised by <a href='https://scholar.google.com/citations?user=cTpFPJgAAAAJ&hl=en'>Prof. Pan Zhou</a>. I had a great time as a research intern at Tecent AI lab at Shenzhen, advised by <a href='https://linchaobao.github.io/'>Linchao Bao</a>. 
                <br>
                <br>
                My research interests are in computer vision and machine learning, with specific interest in 3D detection, pointcloud understanding and crowd counting, etc. Looking for self-motivated interns in Baidu. Please drop your CV to me if you are interested in those topics.
              </p>
              </div>
            </td>
            <td style="padding:10% 3% 3% 3%;width:40%;max-width:40%">
              <a href="images/Lingtengqiu.jpg"><img style="width:80%;max-width:120%" alt="profile photo" src="zouzhikang.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
      </tbody></table>


      <!-- ------------------------ News------------------------------- -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>
            2023.09: One paper accepted by NeurIPS2023.<br>
            2023.07: One paper accepted by ICCV2023.<br>
            2023.02: Two paper accepted by CVPR2023.<br>
            2022.06: Two paper accepted by ACMMM2022.<br>
            2021.07: Two paper accepted by ICCV2021. It is also my first monocular 3D detection paper.<br>
            2021.07: Three paper accepted by ACMMM2021.<br>
            2021.07: One paper accepted by ACMMM2020.<br>
            2020:11: Share paper list about monocular 3D detection in <a href="https://github.com/BigTeacher-777/Awesome-Monocular-3D-detection">Awesome-Monocular-3D-detection</a><br>
            2020.07: Joined Baidu Inc. at Shenzhen as a computer vision researcher. Foucs on 3D Vision.<br>
            2018.12: Joined Tecent AI lab at Shenzhen as research intern. Started doing research on 3D Vision.
            </p>
          </td>
        </tr>
      </tbody></table>


      <!-- ------------------------ Highlight------------------------------- -->
      <table width="100%" align="center" border="0" cellspacing="0" style="padding-top:20px;padding-left:20px;padding-bottom:5px"><tbody>
        <tr> <td>
                <heading>Research Highlight</heading>
          </td> </tr>
      </tbody> </table>

      <table width="100%" align="center" border="0" cellspacing="0" style="padding-top:05px;padding-left:20px;padding-bottom:0px"><tbody>
        <tr> <td>
            <div class="grid-container">
            <div>  <!--grid 1-->
              <a href="">
              <img src="./Highlight/ICCV23_ViT-WSS3D.gif" height="100" alt=""/></a> 
              <p>ICCV23: A Simple Vision Transformer for Weakly Semi-supervised 3D Object Detection</p>
            </div>

            <div> <!--grid 4-->
              <a href="https://arxiv.org/abs/2304.04231">
              <img src="./Highlight/CVPR23_CrowdCLIP.gif" height="100" alt="" /></a>
              <p>CVPR23: CrowdCLIP: Unsupervised Crowd Counting <br> via Vision-Language Model</p>
            </div>

            <div> <!--grid 2-->
              <a href="https://arxiv.org/abs/2207.05497">
              <img src="./Highlight/MM22_SPNet.gif" height="100" alt="" /></a>
              <p>ACM MM22: Paint and Distill: Boosting 3D Object Detection with Semantic Passing Network</p>
            </div>


            <div> <!--grid 5-->
              <a href="https://arxiv.org/abs/2107.12858">
              <img src="./Highlight/MM21_ASNet.gif" height="100" alt="" /></a>
              <p>ACM MM21: Coarse to Fine: Domain Adaptive Crowd Counting via Adversarial Scoring Network</p>
            </div>

            <div> <!--grid 3-->
              <a href="https://arxiv.org/abs/2112.14023">
              <img src="./Highlight/ICCV21_DFRNet.gif" height="100" alt="" /></a> 
              <p style='font-size:13px'>ICCV21: Exploiting Reciprocal Appearance-Localization Features for Monocular 3D Object Detection</p>
            </div>
            
            <div> <!--grid 6-->
              <a href="https://arxiv.org/abs/2104.10868">
              <img src="./Highlight/MM21_APAM.gif" height="100" alt="" /></a>
              <p>ACM MM21: Towards Adversarial Patch Analysis and Certified Defense against Crowd Counting</p>
            </div>
          </div>
          </td> </tr>
      </tbody> </table>



      <!-- ------------------------ publications------------------------------- -->
      <table width="100%" align="center" border="0" cellspacing="0" style="padding-top:20px;padding-left:20px;padding-bottom:5px"><tbody>
        <tr> <td>
                <heading>Publications</heading>  (<strong>*</strong> equal contribution)
          </td> </tr>
      </tbody> </table>



      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      <!-- ----------------------2023 publications------------------------------- -->
      <tr></tr>
      <td style="padding:10px;width:25%;height:80%;vertical-align:middle">
        <div class="one" >
            <img src='./Publications/2023/NeurIPS2023_QTNet.jpg' style="height:100%;width:140%; position: absolute;top: -0%">
        </div>
      </td>

      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Query-based Temporal Fusion with Explicit Motion for 3D Object Detection</papertitle>
          <br>
          Jinghua Hou<strong>*</strong>, Zhe Liu<strong>*</strong>, Dingkang Liang, <strong>Zhikang Zou</strong>, Xiaoqing Ye, Xiang Bai
          <br>
          <em>Neural Information Processing Systems</em>, NeurIPS 2023
          <br>
          <a href="https://nips.cc/virtual/2023/poster/70816">[PDF]</a>
          <a href="https://github.com/AlmoonYsl/QTNet">[Code]</a>
          <a href="">[BibTeX]</a>
          <br>
          <div class="w3-content" style="text-align: justify">
          <p>
          </p>
          </div>
      </td>

      <tr></tr>
      <td style="padding:10px;width:25%;height:80%;vertical-align:middle">
        <div class="one" >
            <img src='./Publications/2023/ICCV23_ViT-WSS3D-temp.png' style="height:100%;width:140%; position: absolute;top: -0%">
        </div>
      </td>

      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>A Simple Vision Transformer for Weakly Semi-supervised 3D Object Detection</papertitle>
          <br>
          Dingyuan Zhang<strong>*</strong>, Dingkang Liang<strong>*</strong>, <strong>Zhikang Zou*</strong>, Jingyu Li, Xiaoqing Ye, Zhe Liu, Xiao Tan, </br> Xiang Bai
          <br>
          <em>IEEE International Conference on Computer Vision</em>, ICCV 2023
          <br>
          <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_A_Simple_Vision_Transformer_for_Weakly_Semi-supervised_3D_Object_Detection_ICCV_2023_paper.pdf">[PDF]</a>
          <a href="">[Code]</a>
          <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:gNZ3MuJ1NUEJ:scholar.google.com/&output=citation&scisdr=ClEEJesLEIurlc36-sI:AFWwaeYAAAAAZWf84sPWDZ-As_c02xvGAdTQz8Y&scisig=AFWwaeYAAAAAZWf84pAdTF6HvfOYnftWAqD2EUQ&scisf=4&ct=citation&cd=-1&hl=zh-CN">[BibTeX]</a>
          <br>
          <div class="w3-content" style="text-align: justify">
          <p>
          </p>
          </div>
      </td>


      <tr></tr>
      <td style="padding:10px;width:25%;height:80%;vertical-align:middle">
        <div class="one" >
            <img src='./Publications/2023/CVPR23_CrowdCLIP.png' style="height:100%;width:140%; position: absolute;top: -0%">
        </div>
      </td>

      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>CrowdCLIP: Unsupervised Crowd Counting via Vision-Language Model</papertitle>
          <br>
          Dingkang Liang<strong>*</strong>, Jiahao Xie<strong>*</strong>, <strong>Zhikang Zou</strong>, Xiaoqing Ye, Wei Xu, Xiang Bai
          <br>
          <em>IEEE Conference on Computer Vision and Pattern Recognition</em>, CVPR 2023
          <br>
          <a href="https://arxiv.org/pdf/2304.04231.pdf">[PDF]</a>
          <a href="https://github.com/dk-liang/CrowdCLIP">[Code]</a>
          <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:s_FUcnNNEYIJ:scholar.google.com/&output=citation&scisdr=CpsWSNIGEP_kqZe1Exw:AJ9-iYsAAAAAZDazCx3xcV1DPu8CYB9ED_JGKQM&scisig=AJ9-iYsAAAAAZDazC2058Jv9urwgkp7mEEqvK38&scisf=4&ct=citation&cd=-1&hl=zh-CN">[BibTeX]</a>
          <br>
          <div class="w3-content" style="text-align: justify">
          <p>
          </p>
          </div>
      </td>

      <tr></tr>
      <td style="padding:10px;width:25%;height:80%;vertical-align:middle">
        <div class="one" >
            <img src='./Publications/2023/CVPR23_SOOD.png' style="height:100%;width:140%; position: absolute;top: -0%">
        </div>
      </td>

      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>SOOD: Towards Semi-Supervised Oriented Object Detection</papertitle>
          <br>
          Wei Hua<strong>*</strong>, Dingkang Liang<strong>*</strong>, Jingyu Li, Xiaolong Liu, <strong>Zhikang Zou</strong>, Xiaoqing Ye, Xiang Bai
          <br>
          <em>IEEE Conference on Computer Vision and Pattern Recognition</em>, CVPR 2023
          <br>
          <a href="https://arxiv.org/pdf/2304.04515.pdf">[PDF]</a>
          <a href="https://github.com/HamPerdredes/SOOD">[Code]</a>
          <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:0Wa3QDcyDqwJ:scholar.google.com/&output=citation&scisdr=CpsWSNIGEP_kqZe0RQ8:AJ9-iYsAAAAAZDayXQ5OPSC0i8vkgP3mjyntyRY&scisig=AJ9-iYsAAAAAZDayXVlwWutB5Ahjm3NtQx5kf1Q&scisf=4&ct=citation&cd=-1&hl=zh-CN">[BibTeX]</a>
          <br>
          <div class="w3-content" style="text-align: justify">
          <p>
          </p>
          </div>
      </td>


      <!-- ----------------------2022 publications------------------------------- -->
      <tr></tr>
      <td style="padding:10px;width:25%;height:80%;vertical-align:middle">
        <div class="one" >
            <img src='./Publications/2022/MM22_SPNet.png' style="height:100%;width:140%; position: absolute;top: -0%">
        </div>
      </td>

      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Paint and Distill: Boosting 3D Object Detection with Semantic Passing Network</papertitle>
          <br>
          Bo Ju<strong>*</strong>, <strong>Zhikang Zou*</strong>, Xiaoqing Ye, Minyue Jiang, Xiao Tan, Errui Ding, Jingdong Wang
          <br>
          <em>ACM International Conference on Multimedia</em>, ACM MM 2022
          <br>
          <a href="https://arxiv.org/abs/2207.05497">[PDF]</a>
          <a href="https://github.com/jb892/SPNet">[Code]</a>
          <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:Lq9-1dTcpFIJ:scholar.google.com/&output=citation&scisdr=CgXuEgKHEPGMqp7XEeo:AAGBfm0AAAAAZAXRCerZ8xBvjL79_yiRm5DHuK7AQfYl&scisig=AAGBfm0AAAAAZAXRCYLkmQRdAe-7yDtHBdDV3z6WXJM2&scisf=4&ct=citation&cd=-1&hl=zh-CN">[BibTeX]</a>
          <br>
          <div class="w3-content" style="text-align: justify">
          <p>
          </p>
          </div>
      </td>


      <tr></tr>
      <td style="padding:10px;width:25%;vertical-align:middle">
          <div class="one" >
              <img src='./Publications/2022/MM22_RIL.png' style="height:100%;width:140%; position: absolute;top: -0%">
          </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Repainting and Imitating Learning for Lane Detection</papertitle>
          <br>
          Yue He<strong>*</strong>, Minyue Jiang<strong>*</strong>, Xiaoqing Ye<strong>*</strong>, Liang Du<strong>*</strong>, <strong>Zhikang Zou</strong>, Wei Zhang, Xiao Tan, <br> Errui Ding
          <br>
          <em>ACM International Conference on Multimedia</em>, ACM MM 2022 
          <br>
          <a href="https://dl.acm.org/doi/10.1145/3503161.3548042">[PDF]</a>
	        <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:uX7s70bfSPoJ:scholar.google.com/&output=citation&scisdr=CgXuEgKHEPGMqp7U48o:AAGBfm0AAAAAZAXS-8qnFI5qdxO7pGPcRoRZAca1ra97&scisig=AAGBfm0AAAAAZAXS--46hTccUkXX9VLe5V_huvSEZXOE&scisf=4&ct=citation&cd=-1&hl=zh-CN">[BibTeX]</a>
          <br>
          <div class="w3-content" style="text-align: justify">
          <p>
          </p>
          </div>
      </td>


      <tr></tr>
      <td style="padding:10px;width:20%;vertical-align:middle">
          <div class="one" >
              <img src='./Publications/2022/RAL22_SGM3D.png' style="height:100%;width:140%; position: absolute;top: -0%">
          </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>SGM3D: Stereo Guided Monocular 3D Object Detection</papertitle>
          <br>
          Zheyuan Zhou<strong>*</strong>, Liang Du<strong>*</strong>, Xiaoqing Ye<strong>*</strong>, <strong>Zhikang Zou</strong>, Xiao Tan, Li Zhang, Xiangyang Xue, Jianfeng Feng
          <br>
          <em>IEEE Robotics and Automation Letters</em>, RA-L 2022
          <br>
          <!-- <a href="https://kv2000.github.io/2022/03/28/reef/">[Project]</a> -->
          <a href="https://arxiv.org/pdf/2112.01914.pdf">[PDF]</a>
          <a href="https://github.com/zhouzheyuan/sgm3d">[Code]</a>
          <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:LtxWtW-i-OIJ:scholar.google.com/&output=citation&scisdr=CgXuEgKHEPGMqp7SGZI:AAGBfm0AAAAAZAXUAZIeWMxWk0tJ1_Sff4YK-ijLSMHd&scisig=AAGBfm0AAAAAZAXUAaJwDAsRlYci98pO7bqcAlA_Lymb&scisf=4&ct=citation&cd=-1&hl=zh-CN">[BibTeX]</a>
          <br>
          <div class="w3-content" style="text-align: justify">
          <p> 
          </p>
          </div>
      </td>

      <!-- ----------------------2021 publications------------------------------- -->
      <tr></tr>
      <td style="padding:10px;width:25%;vertical-align:middle">
        <div class="one" >
            <img src='./Publications/2021/ICCV21_DFRNet.jpeg' style="height:100%;width:140%; position: absolute;top: -0%">
        </div>
      </td>

      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>The Devil is in the Task: Exploiting Reciprocal Appearance-Localization Features for Monocular 3D Object Detection</papertitle>
          <br>
          <strong>Zhikang Zou*</strong>, Xiaoqing Ye<strong>*</strong>, Liang Du<strong>*</strong>, Xianhui Cheng<strong>*</strong>, Xiao Tan, Li Zhang, Jianfeng Feng, Xiangyang Xue, Errui Ding
          <br>
          <em>IEEE International Conference on Computer Vision</em>, ICCV 2021
          <br>
          <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Zou_The_Devil_Is_in_the_Task_Exploiting_Reciprocal_Appearance-Localization_Features_ICCV_2021_paper.html">[PDF]</a>
          <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:RlkoFJuryScJ:scholar.google.com/&output=citation&scisdr=CgXuEgKHEPGMqp3bXVE:AAGBfm0AAAAAZAbdRVFtb4sBVMbWR5nsiDid9AqnEIQ2&scisig=AAGBfm0AAAAAZAbdRVM4Y-8HGujd7w_re8G2y26DPgT2&scisf=4&ct=citation&cd=-1&hl=zh-CN">[BibTeX]</a>
          <br>
          <div class="w3-content" style="text-align: justify">
          <p>
          </p>
          </div>
      </td>


      <tr></tr>
      <td style="padding:10px;width:25%;vertical-align:middle">
        <div class="one" >
            <img src='./Publications/2021/ICCV21_depth.png' style="height:100%;width:140%; position: absolute;top: -0%">
        </div>
      </td>

      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Revealing the Reciprocal Relations between Self-Supervised Stereo and Monocular Depth Estimation</papertitle>
          <br>
          Zhi Chen<strong>*</strong>, Xiaoqing Ye<strong>*</strong>, Wei Yang, Zhenbo Xu, Xiao Tan, <strong>Zhikang Zou</strong>, Errui Ding, Xinming Zhang, Liusheng Huang
          <br>
          <em>IEEE International Conference on Computer Vision</em>, ICCV 2021
          <br>
          <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Chen_Revealing_the_Reciprocal_Relations_Between_Self-Supervised_Stereo_and_Monocular_Depth_ICCV_2021_paper.html">[PDF]</a>
          <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:mTNwNZZOoocJ:scholar.google.com/&output=citation&scisdr=CgXuEgKHEPGMqp3vd4Q:AAGBfm0AAAAAZAbpb4Sc25WzJQbDuBrCnpxVNtzeneF0&scisig=AAGBfm0AAAAAZAbpby1I_LcX9Mq8DSao0WgC9JltE5lw&scisf=4&ct=citation&cd=-1&hl=zh-CN">[BibTeX]</a>
          <br>
          <div class="w3-content" style="text-align: justify">
          <p>
          </p>
          </div>
      </td>


      <tr></tr>
      <td style="padding:10px;width:25%；vertical-align:middle">
        <div class="one" >
            <img src='./Publications/2021/MM21_ASNet.png' style="height:100%;width:140%; position: absolute;top: -0%">
        </div>
      </td>

      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Coarse to Fine: Domain Adaptive Crowd Counting via Adversarial Scoring Network</papertitle>
          <br>
          <strong>Zhikang Zou*</strong>, Xiaoye Qu<strong>*</strong>, Pan Zhou, Shuangjie Xu, Xiaoqing Ye, Wenhao Wu, Jin Ye
          <br>
          <em>ACM International Conference on Multimedia</em>, ACM MM 2021 
          <br>
          <a href="https://arxiv.org/abs/2107.12858">[PDF]</a>
          <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:OhMlJFUO9PwJ:scholar.google.com/&output=citation&scisdr=CgXuEgKHEPGMqp30xww:AAGBfm0AAAAAZAby3wxoXQe-Eiw05CFREZA_bnDLwjtT&scisig=AAGBfm0AAAAAZAby3zyHp5tgx5rpIyKisyf4ykbxd1tx&scisf=4&ct=citation&cd=-1&hl=zh-CN">[BibTeX]</a>
          <br>
          <div class="w3-content" style="text-align: justify">
          <p>
          </p>
          </div>
      </td>


      <tr></tr>
      <td style="padding:10px;width:25%；vertical-align:middle">
        <div class="one" >
            <img src='./Publications/2021/MM21_APAM.png' style="height:100%;width:140%; position: absolute;top: -0%">
        </div>
      </td>

      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Towards Adversarial Patch Analysis and Certified Defense against Crowd Counting</papertitle>
          <br>
          Qiming Wu<strong>*</strong>, <strong>Zhikang Zou*</strong>, Pan Zhou, Xiaoqing Ye, Binghui Wang, Ang Li
          <br>
          <em>ACM International Conference on Multimedia</em>, ACM MM 2021 
          <br>
          <a href="https://arxiv.org/abs/2104.10868">[PDF]</a>
          <a href="https://github.com/harrywuhust2022/Adv-Crowd-analysis">[Code]</a>
          <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:6JDbAStTNVAJ:scholar.google.com/&output=citation&scisdr=CgXuEgKHEPGMqp3wgJE:AAGBfm0AAAAAZAb2mJFicVOYT1KQwgDsDRr6yjdBauiu&scisig=AAGBfm0AAAAAZAb2mND_wheBL3JlVVwK9rTAT_D_taKS&scisf=4&ct=citation&cd=-1&hl=zh-CN">[BibTeX]</a>
          <br>
          <div class="w3-content" style="text-align: justify">
          <p>
          </p>
          </div>
      </td>


      <tr></tr>
      <td style="padding:10px;width:25%；vertical-align:middle">
        <div class="one" >
            <img src='./Publications/2020/ECCV20_BOP.jpg' style="height:100%;width:140%; position: absolute;top: -0%">
        </div>
      </td>

      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Leaping from 2D Detection to Efficient 6DoF Object Pose Estimation</papertitle>
          <br>
          Jinhui Liu<strong>*</strong>, <strong>Zhikang Zou*</strong>, Xiaoqing Ye<strong>*</strong>, Xiao Tan, Errui Ding, Feng Xu, Xin Yu
          <br>
          <em>European Conference on Computer Vision</em>, ECCVw 2020
          <br>
          <a href="https://link.springer.com/chapter/10.1007/978-3-030-66096-3_47">[PDF]</a>
          <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:zI4DmfJ98EAJ:scholar.google.com/&output=citation&scisdr=CgXuEgKHEPGMqpJfrLM:AAGBfm0AAAAAZAlZtLO-RUVfB4Iu8MhHz2zg4TYgBJCA&scisig=AAGBfm0AAAAAZAlZtEmw1UrGljRh48QpvhsdSOrptDsm&scisf=4&ct=citation&cd=-1&hl=zh-CN">[BibTeX]</a>
          <br>
          <div class="w3-content" style="text-align: justify">
          <p>
          </p>
          </div>
      </td>


      <tr></tr>
      <td style="padding:10px;width:25%；vertical-align:middle">
        <div class="one" >
            <img src='./Publications/2020/ECAI20_HSRNet.jpg' style="height:100%;width:140%; position: absolute;top: -0%">
        </div>
      </td>

      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Crowd Counting via Hierarchical Scale Recalibration Network</papertitle>
          <br>
          <strong>Zhikang Zou*</strong>, Yifan Liu<strong>*</strong>, Shuangjie Xu, Wei Wei, Shiping Wen, Pan Zhou
          <br>
          <em>European Conference on Artificial Intelligence</em>, ECAI 2020
          <br>
          <a href="https://arxiv.org/abs/2003.03545">[PDF]</a>
          <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:Zh05n1MfvfEJ:scholar.google.com/&output=citation&scisdr=CgXuEgKHEPGMqpJRhQM:AAGBfm0AAAAAZAlXnQOMaPtzdhNBXA9lJ5sTpyuXqnZF&scisig=AAGBfm0AAAAAZAlXnaMNOkuBMcIYesJr6oKplti5F2x4&scisf=4&ct=citation&cd=-1&hl=zh-CN">[BibTeX]</a>
          <br>
          <div class="w3-content" style="text-align: justify">
          <p>
          </p>
          </div>
      </td>


      <tr></tr>
      <td style="padding:10px;width:25%；vertical-align:middle">
        <div class="one" >
            <img src='./Publications/2019/BMVC19_E3D.jpg' style="height:100%;width:140%; position: absolute;top: -0%">
        </div>
      </td>

      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Enhanced 3D Convolutional Networks for Crowd Counting</papertitle>
          <br>
          <strong>Zhikang Zou*</strong>, Huiliang Shao<strong>*</strong>, Xiaoye Qu, Wei Wei, Pan Zhou
          <br>
          <em>British Machine Vision Conference</em>, BMVC 2019
          <br>
          <a href="https://arxiv.org/abs/1908.04121">[PDF]</a>
          <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:MzuTY55garMJ:scholar.google.com/&output=citation&scisdr=CgXuEgKHEPGMqpJcm-w:AAGBfm0AAAAAZAlag-whnM_eUgmceaaEtzohMJLygCR9&scisig=AAGBfm0AAAAAZAlag7e1NA181Vedx9fq5HSBKF_OS_Tt&scisf=4&ct=citation&cd=-1&hl=zh-CN">[BibTeX]</a>
          <br>
          <div class="w3-content" style="text-align: justify">
          <p>
          </p>
          </div>
      </td>


      <tr></tr>
      <td style="padding:10px;width:25%；vertical-align:middle">
        <div class="one" >
            <img src='./Publications/2019/NAACL19_ACAN.jpg' style="height:100%;width:140%; position: absolute;top: -0%">
        </div>
      </td>

      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Adversarial Category Alignment Network for Cross-domain Sentiment Classification</papertitle>
          <br>
          Xiaoye Qu<strong>*</strong>, <strong>Zhikang Zou*</strong>, Yu Cheng, Yang Yang, Pan Zhou
          <br>
          <em>Annual Conference of the North American Chapter of the Association for Computational Linguistics</em>, NAACL 2019
          <br>
          <a href="https://aclanthology.org/N19-1258/">[PDF]</a>
          <a href="https://github.com/XiaoYee/ACAN">[Code]</a>
          <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:5lgBoIvhLwYJ:scholar.google.com/&output=citation&scisdr=CgXuEgKHEPGMqpJaT8Y:AAGBfm0AAAAAZAlcV8aTEYRPAWTMdjYTcQZpfS12S7Gs&scisig=AAGBfm0AAAAAZAlcV7NAuX3PjOGL0tS8sIPOHo2ZsdYc&scisf=4&ct=citation&cd=-1&hl=zh-CN">[BibTeX]</a>
          <br>
          <div class="w3-content" style="text-align: justify">
          <p>
          </p>
          </div>
      </td>



      <!-- ----------------------Contest------------------------------- -->
      <table width="100%" align="center" border="0" cellspacing="0" style="padding-top:20px;padding-left:10px;padding-bottom:0px"><tbody>

      <tr>
        <td style="padding:10px;width:100%;vertical-align:middle">
          <heading>Contest</heading>
        </td>
      </tr>
      </tbody></table>

      <table style="width:100%;border:0px; border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      <tr></tr>
      <td style="padding:10px;width:25%;vertical-align:middle">
            <div class="one" >
              <div class="one" >
                <img src='./Contest/Argoverse2021.jpeg' style="height:100%;width:140%; position: absolute;top: -0%">
              </div>
              </video>
          </div>
      </td>
      <td style="padding:20px ;width:75%;vertical-align:middle">
          <papertitle>Argoverse Stereo Competition 2021</papertitle><br>
          <strong>Topic---</strong>Stereo Matching</br>
          <em>The IEEE Conference on Computer Vision and Pattern Recognition</em>, CVPR 2021<br>
          Rank <strong>2nd</strong> in the contest
      </td>

      <tr></tr>
      <td style="padding:10px;width:25%;vertical-align:middle">
            <div class="one" >
              <div class="one" >
                <img src='./Contest/ECCV20_BOPChallenge.png' style="height:100%;width:140%; position: absolute;top: -0%">
              </div>
              </video>
          </div>
      </td>
      <td style="padding:20px ;width:75%;vertical-align:middle">
          <papertitle>BOP Challenge 2020</papertitle><br>
          <strong>Topic---</strong>6D Pose Estimation</br>
          <em>European Conference on Computer Vision</em>, ECCV 2020<br>
          Rank <strong>3nd</strong> in the contest
      </td>


      <table width="100%" align="center" border="0" cellspacing="0" style="padding-top:20px;padding-left:10px;padding-bottom:5px"><tbody>
        <tr> <td>
            <heading>Current/Past Intern</heading>
          </td> </tr>
      </tbody> </table>
      <table width="100%" align="center" border="0" cellspacing="0" style="padding-top:00px;padding-left:20px;padding-bottom:5px"><tbody>
        <tr> <td>
            • <a href='https://dk-liang.github.io/'>Dingkang Liang</a>, PhD student at HUST advised by Prof. Xiang Bai</br>
            • <a href='https://scholar.google.com/citations?user=PJ9x-6AAAAAJ&hl=zh-CN&oi=ao'>Yubo Cui</a>, PhD student at NEU advised by Prof. Zheng Fang</br>
            • <a href='https://www.linkedin.cn/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.cn%2Finjobs%2Fin%2Ffanbin-lu-09b763219'>Fanbin Lu</a>, PhD student at CUHK advised by Prof. Jiaya Jia </br>
            • <a href='https://mayuelala.github.io/'>Yue Ma</a>, Master student at Tsinghua advised by Prof. Xiu Li</br>
            • <a href='https://github.com/KuofengGao'>Kuofeng Gao</a>, Master student at Tsinghua</br>
          </td> </tr>
      </tbody>
   

    
      </table>



</body>

</html>
